{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Used for selecting the 6 best features per cluster\n",
    "* We're using mean squared error of each variable vs. the ALSFRS_score, and take the best 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>family_ALS_hist_last</th>\n",
       "      <th>weight_mean</th>\n",
       "      <th>weight_median</th>\n",
       "      <th>weight_std</th>\n",
       "      <th>weight_pct_diff</th>\n",
       "      <th>weight_mean_slope</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>Age_last</th>\n",
       "      <th>...</th>\n",
       "      <th>bp_diastolic_std</th>\n",
       "      <th>bp_diastolic_pct_diff</th>\n",
       "      <th>bp_diastolic_mean_slope</th>\n",
       "      <th>Creatinine_mean</th>\n",
       "      <th>Creatinine_median</th>\n",
       "      <th>Creatinine_std</th>\n",
       "      <th>Creatinine_pct_diff</th>\n",
       "      <th>Creatinine_last</th>\n",
       "      <th>Creatinine_mean_slope</th>\n",
       "      <th>fvc_percent_pct_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubjectID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.620202</td>\n",
       "      <td>-1.617145</td>\n",
       "      <td>-0.435513</td>\n",
       "      <td>-0.232289</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>1.322796</td>\n",
       "      <td>-1.322796</td>\n",
       "      <td>0.941297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345707</td>\n",
       "      <td>0.099808</td>\n",
       "      <td>-0.109689</td>\n",
       "      <td>0.547815</td>\n",
       "      <td>0.558684</td>\n",
       "      <td>-1.276692</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>0.563661</td>\n",
       "      <td>0.175924</td>\n",
       "      <td>-1.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.086445</td>\n",
       "      <td>-0.100773</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>0.218932</td>\n",
       "      <td>0.466682</td>\n",
       "      <td>1.322796</td>\n",
       "      <td>-1.322796</td>\n",
       "      <td>-0.558473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053767</td>\n",
       "      <td>-0.019317</td>\n",
       "      <td>-0.127591</td>\n",
       "      <td>-1.117773</td>\n",
       "      <td>-0.958224</td>\n",
       "      <td>-0.357095</td>\n",
       "      <td>-0.023280</td>\n",
       "      <td>-0.863703</td>\n",
       "      <td>0.449074</td>\n",
       "      <td>-0.037980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.246644</td>\n",
       "      <td>1.224432</td>\n",
       "      <td>-0.325885</td>\n",
       "      <td>0.340632</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>-0.755549</td>\n",
       "      <td>0.755549</td>\n",
       "      <td>-1.440691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526932</td>\n",
       "      <td>0.462695</td>\n",
       "      <td>-0.993015</td>\n",
       "      <td>1.060304</td>\n",
       "      <td>1.064321</td>\n",
       "      <td>-1.276692</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>1.039449</td>\n",
       "      <td>0.175924</td>\n",
       "      <td>0.993322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924490</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>-0.796321</td>\n",
       "      <td>-0.047759</td>\n",
       "      <td>-0.067460</td>\n",
       "      <td>-0.755549</td>\n",
       "      <td>0.755549</td>\n",
       "      <td>0.764854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254585</td>\n",
       "      <td>-1.489507</td>\n",
       "      <td>-0.724060</td>\n",
       "      <td>-0.220918</td>\n",
       "      <td>-0.199770</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>-0.022054</td>\n",
       "      <td>0.087873</td>\n",
       "      <td>0.437748</td>\n",
       "      <td>-0.361454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.702551</td>\n",
       "      <td>-0.700194</td>\n",
       "      <td>-0.487343</td>\n",
       "      <td>-0.149486</td>\n",
       "      <td>-0.553742</td>\n",
       "      <td>1.322796</td>\n",
       "      <td>-1.322796</td>\n",
       "      <td>0.764854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127369</td>\n",
       "      <td>-0.186248</td>\n",
       "      <td>0.910351</td>\n",
       "      <td>-0.861529</td>\n",
       "      <td>-0.958224</td>\n",
       "      <td>-0.357095</td>\n",
       "      <td>-0.023579</td>\n",
       "      <td>-0.387915</td>\n",
       "      <td>0.214460</td>\n",
       "      <td>0.661195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster  family_ALS_hist_last  weight_mean  weight_median  \\\n",
       "SubjectID                                                              \n",
       "533              2                     0    -1.620202      -1.617145   \n",
       "649              0                     0    -0.086445      -0.100773   \n",
       "1234             1                     0     1.246644       1.224432   \n",
       "2492             0                     0     0.924490       0.916621   \n",
       "2956             2                     0    -0.702551      -0.700194   \n",
       "\n",
       "           weight_std  weight_pct_diff  weight_mean_slope         F         M  \\\n",
       "SubjectID                                                                       \n",
       "533         -0.435513        -0.232289          -0.002066  1.322796 -1.322796   \n",
       "649         -0.163334         0.218932           0.466682  1.322796 -1.322796   \n",
       "1234        -0.325885         0.340632           0.124007 -0.755549  0.755549   \n",
       "2492        -0.796321        -0.047759          -0.067460 -0.755549  0.755549   \n",
       "2956        -0.487343        -0.149486          -0.553742  1.322796 -1.322796   \n",
       "\n",
       "           Age_last          ...           bp_diastolic_std  \\\n",
       "SubjectID                    ...                              \n",
       "533        0.941297          ...                   0.345707   \n",
       "649       -0.558473          ...                  -1.053767   \n",
       "1234      -1.440691          ...                   0.526932   \n",
       "2492       0.764854          ...                   0.254585   \n",
       "2956       0.764854          ...                   0.127369   \n",
       "\n",
       "           bp_diastolic_pct_diff  bp_diastolic_mean_slope  Creatinine_mean  \\\n",
       "SubjectID                                                                    \n",
       "533                     0.099808                -0.109689         0.547815   \n",
       "649                    -0.019317                -0.127591        -1.117773   \n",
       "1234                    0.462695                -0.993015         1.060304   \n",
       "2492                   -1.489507                -0.724060        -0.220918   \n",
       "2956                   -0.186248                 0.910351        -0.861529   \n",
       "\n",
       "           Creatinine_median  Creatinine_std  Creatinine_pct_diff  \\\n",
       "SubjectID                                                           \n",
       "533                 0.558684       -1.276692            -0.025200   \n",
       "649                -0.958224       -0.357095            -0.023280   \n",
       "1234                1.064321       -1.276692            -0.025200   \n",
       "2492               -0.199770        0.023815            -0.022054   \n",
       "2956               -0.958224       -0.357095            -0.023579   \n",
       "\n",
       "           Creatinine_last  Creatinine_mean_slope  fvc_percent_pct_diff  \n",
       "SubjectID                                                                \n",
       "533               0.563661               0.175924             -1.864018  \n",
       "649              -0.863703               0.449074             -0.037980  \n",
       "1234              1.039449               0.175924              0.993322  \n",
       "2492              0.087873               0.437748             -0.361454  \n",
       "2956             -0.387915               0.214460              0.661195  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data = pd.read_csv('../train_data_vectorized.csv', sep='|', index_col=0)\n",
    "slope = pd.read_csv('../train_slope.csv', sep = '|', index_col=0)\n",
    "clusters = pd.read_csv('../train_kmeans_clusters.csv', sep = '|', index_col=0)\n",
    "all_feature_metadata = pickle.load( open('../all_feature_metadata.pickle', 'rb') )\n",
    "\n",
    "X = clusters.join(vectorized_data)\n",
    "Y = clusters.join(slope)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Age', 'BMI', 'Gender', 'family_ALS_hist', 'fvc_percent', 'height'],\n",
       " 1: ['Age', 'BMI', 'Gender', 'Race', 'height', 'pulse'],\n",
       " 2: ['Age', 'BMI', 'Gender', 'Race', 'family_ALS_hist', 'height']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_per_cluster = {}\n",
    "\n",
    "for c in clusters['cluster'].unique():\n",
    "    seg_X, seg_Y = X[X['cluster'] == c], Y[Y['cluster'] == c]\n",
    "    seg_Y = seg_Y.fillna(seg_Y.mean())\n",
    "    \n",
    "    score_per_feature = {}\n",
    "    \n",
    "    for feature, fm in all_feature_metadata.iteritems():\n",
    "        regr = linear_model.LinearRegression()\n",
    "        X_feature_fam = seg_X[list(fm[\"derived_features\"])]\n",
    "        regr.fit(X_feature_fam, seg_Y)\n",
    "        score_per_feature[feature] = regr.score(X_feature_fam, seg_Y)\n",
    "    \n",
    "    best_features_per_cluster[c] = sorted(sorted(score_per_feature, key=score_per_feature.get)[:6])\n",
    "    \n",
    "best_features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../best_features_per_cluster.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(best_features_per_cluster, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply the selector \n",
    "leave only the best features per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "df (1138647, 5)\n",
      "clusters (1777, 1)\n",
      "0 (391149, 6) (8260, 6)\n",
      "1 (341999, 6) (7368, 6)\n",
      "2 (405499, 6) (3051, 6)\n",
      "test\n",
      "df (126664, 5)\n",
      "clusters (600, 1)\n",
      "0 (43544, 6) (1567, 6)\n",
      "1 (33947, 6) (1312, 6)\n",
      "2 (49173, 6) (1099, 6)\n"
     ]
    }
   ],
   "source": [
    "for t in [\"train\", \"test\"]:\n",
    "    print t\n",
    "    df = pd.read_csv('../' + t + '_data.csv', sep = '|', index_col=\"SubjectID\", dtype='unicode')\n",
    "    print \"df\", df.shape\n",
    "    clusters = pd.read_csv('../' + t + '_kmeans_clusters.csv', sep = '|', index_col=\"SubjectID\")\n",
    "    print \"clusters\", clusters.shape\n",
    "    j = df.join(clusters)\n",
    "    buf, is_first = \"\", True\n",
    "    for c, features in best_features_per_cluster.iteritems():\n",
    "        slice = j[j.cluster == c]\n",
    "        selected = slice[slice.feature_name.isin(features)]\n",
    "        print c, slice.shape, selected.shape\n",
    "        buf += selected.to_csv(sep='|', header = is_first, columns=df.columns)\n",
    "        is_first = False\n",
    "    with open('../' + t + '_data_selected.csv','w') as f:\n",
    "        f.write(buf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run selector.sh\n",
    "As specified in the challenge - we must run our selector logic subject by subject.\n",
    "\n",
    "The output_file_path must have the following format:\n",
    "* First line: the cluster identifier for that patient\n",
    "* Following lines: the selected features selected for that specific single patient, using the same format as the input data. A maximum of 6 features are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0\n",
      "750059|Demographic|Gender|M||0.0\n",
      "750059|Demographic|Age|54||0.0\n",
      "750059|Vitals|height|195.58|cm|0.0\n",
      "750059|Vitals|BMI|0.00282223686053039||0.0\n",
      "\n",
      "cluster: 2\n",
      "750094|Demographic|Gender|F||0.0\n",
      "750094|Demographic|Age|64||0.0\n",
      "750094|Demographic|Race|White||0.0\n",
      "750094|Vitals|height|158.0|cm|0.0\n",
      "750094|Vitals|height|158.0|cm|8.0\n",
      "\n",
      "cluster: 2\n",
      "750148|Demographic|Gender|F||0.0\n",
      "750148|Demographic|Age|67||0.0\n",
      "750148|Demographic|Race|White||0.0\n",
      "750148|Vitals|height|160.0|cm|0.0\n",
      "750148|Vitals|BMI|0.0022421875||0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from vectorizing_funcs import *\n",
    "\n",
    "all_feature_metadata = pickle.load( open('../all_feature_metadata.pickle', 'rb') )\n",
    "train_data_means = pickle.load( open('../train_data_means.pickle', 'rb') )\n",
    "train_data_std = pickle.load( open('../train_data_std.pickle', 'rb') )\n",
    "clustering_model = pickle.load( open('../clustering_model.pickle', 'rb') )\n",
    "best_features_per_cluster = pickle.load( open('../best_features_per_cluster.pickle', 'rb') )\n",
    "\n",
    "\n",
    "t = \"test\"\n",
    "df = pd.read_csv('../' + t + '_data.csv', sep = '|', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "for subj in df.SubjectID.unique()[:3]:\n",
    "    df_subj = df[df.SubjectID == subj]\n",
    "    vectorized, _ = vectorize(df_subj, all_feature_metadata)\n",
    "    normalized, _ = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "    cluster_data = normalized[clustering_model[\"columns\"]]\n",
    "    c = clustering_model[\"model\"].predict(cluster_data)[0]\n",
    "    buf = \"cluster: %d\\n\" % c\n",
    "    selected = df_subj[df_subj.feature_name.isin(best_features_per_cluster[c])]\n",
    "    buf += selected.to_csv(sep='|', index = False, header = False)\n",
    "    print buf\n",
    "    with open('../selected_' + subj + \".txt\", \"wb\") as f:\n",
    "        f.write(buf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
