{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Builds all our models x-validated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from StringIO import StringIO\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_validation, grid_search\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from vectorizing_funcs import *\n",
    "from modeling_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:  (1642927, 6) 2424\n",
      "slope:  (2424, 1) 2424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>form_name</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_value</th>\n",
       "      <th>feature_unit</th>\n",
       "      <th>feature_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>533</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Gender</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>533</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Age</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubjectID    form_name feature_name feature_value feature_unit feature_delta\n",
       "0       533  Demographic       Gender             F          NaN           0.0\n",
       "1       533  Demographic          Age            65          NaN           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALSFRS_slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubjectID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>-0.965608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>-0.921717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ALSFRS_slope\n",
       "SubjectID              \n",
       "533           -0.965608\n",
       "649           -0.921717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../all_data.csv', sep = '|', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "slope = pd.read_csv('../all_slope.csv', sep = '|', index_col=\"SubjectID\")\n",
    "slope.index = slope.index.astype(str)\n",
    "\n",
    "print \"df: \", df.shape, df.SubjectID.unique().size\n",
    "print \"slope: \", slope.shape, slope.index.unique().size\n",
    "display(df.head(2))\n",
    "display(slope.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_on_test(test_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                 clustering_columns, bins, forest, best_features_per_cluster, model_per_cluster):\n",
    "    \n",
    "    # Vectorizing\n",
    "    vectorized, _ = vectorize(test_data, all_feature_metadata)\n",
    "    normalized, _ = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "    \n",
    "    print \"applying on: \", normalized.shape\n",
    "    \n",
    "    # Clustering\n",
    "    \n",
    "    for_clustering = normalized\n",
    "    clusters = pd.DataFrame(index = for_clustering.index.astype(str))\n",
    "    clusters['cluster'] = np.digitize(forest.predict(for_clustering), bins)\n",
    "    print \"applied cluster cnt: \", np.bincount(clusters.cluster)\n",
    "\n",
    "    X = normalized.join(clusters)\n",
    "    \n",
    "    buf = filter_only_selected_features(test_data.set_index(\"SubjectID\"), clusters, \\\n",
    "                                        best_features_per_cluster)    \n",
    "    s_df = pd.read_csv(StringIO(buf), sep='|', index_col=False, dtype='unicode')\n",
    "    s_vectorized, _ = vectorize(s_df, all_feature_metadata)\n",
    "    s_normalized, _ = normalize(s_vectorized, all_feature_metadata, train_data_means, train_data_std)    \n",
    "    input_for_model = s_normalized.join(clusters)    \n",
    "    \n",
    "    pred = input_for_model.apply(apply_model, args=[model_per_cluster], axis = 1)\n",
    "    return input_for_model, pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_it(train_data, my_n_clusters):\n",
    "        global ts_funcs_to_features\n",
    "        # Prepare metadata\n",
    "        ts_funcs_to_features = add_frequent_lab_tests_to_ts_features(train_data, ts_funcs_to_features)\n",
    "        all_feature_metadata = invert_func_to_features(ts_funcs_to_features, \"ts\")\n",
    "        all_feature_metadata.update(invert_func_to_features(dummy_funcs_to_features, \"dummy\"))\n",
    "        all_feature_metadata = learn_to_dummies_model(train_data, all_feature_metadata)\n",
    "        \n",
    "        # Vectorizing\n",
    "        vectorized, all_feature_metadata = vectorize(train_data, all_feature_metadata)\n",
    "        train_data_means = vectorized.mean()\n",
    "        train_data_std = vectorized.std()            \n",
    "        normalized, all_feature_metadata = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "\n",
    "        everybody = normalized.join(slope)\n",
    "        X = everybody.drop(['ALSFRS_slope'], 1)\n",
    "        Y = everybody[['ALSFRS_slope']]\n",
    "        print \"train_data: \", X.shape, Y.shape\n",
    "        \n",
    "        # Clustering\n",
    "        #for_clustering = normalized[clustering_columns]\n",
    "        #kmeans = KMeans(init='k-means++', n_clusters=my_n_clusters)\n",
    "        #clusters['cluster'] = kmeans.fit_predict(for_clustering)\n",
    "\n",
    "        forest = grid_search.GridSearchCV(RandomForestRegressor(min_samples_leaf=60, min_samples_split=260, random_state=0), \n",
    "                               {'min_samples_leaf': range(60,61,10), 'n_estimators': [1000]})\n",
    "        forest.fit(X, Y.ALSFRS_slope)\n",
    "        bins = np.percentile(forest.predict(X), range(20,100,20))\n",
    "                          \n",
    "        # Note we must convert to str to join with slope later\n",
    "        clusters = pd.DataFrame(index = normalized.index.astype(str))\n",
    "        clusters['cluster'] = np.digitize(forest.predict(X), bins)\n",
    "        print \"train cluster cnt: \", np.bincount(clusters.cluster)\n",
    "\n",
    "        X = X.join(clusters)\n",
    "        Y = Y.join(clusters)\n",
    "\n",
    "        best_features_per_cluster = stepwise_best_features_per_cluster(X, Y, all_feature_metadata)\n",
    "        print \"best_features_per_cluster: \", best_features_per_cluster \n",
    "        buf = filter_only_selected_features(train_data.set_index(\"SubjectID\"), clusters, \\\n",
    "                                            best_features_per_cluster)\n",
    "\n",
    "        s_df = pd.read_csv(StringIO(buf), sep='|', index_col=False, dtype='unicode')\n",
    "        s_vectorized, _ = vectorize(s_df, all_feature_metadata)\n",
    "        s_normalized, _ = normalize(s_vectorized, all_feature_metadata, train_data_means, train_data_std)    \n",
    "        s_X = s_normalized.join(clusters)\n",
    "        \n",
    "        model_per_cluster = get_model_per_cluster(s_X, Y)\n",
    "        \n",
    "        return all_feature_metadata, train_data_means, train_data_std, \\\n",
    "                     bins, forest, best_features_per_cluster, model_per_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_and_test(df, slope, my_n_clusters=2):\n",
    "    kf = KFold(df.SubjectID.unique().size, n_folds=3)\n",
    "    fold, test_rmse, train_rmse = 0, 0.0, 0.0\n",
    "\n",
    "    for train, test in kf:\n",
    "        train_data = df[df.SubjectID.isin(df.SubjectID.unique()[train])]\n",
    "        test_data = df[df.SubjectID.isin(df.SubjectID.unique()[test])]\n",
    "        print\n",
    "        print \"*\"*30\n",
    "        print \"fold: %d\" % fold\n",
    "        tick = datetime.now()\n",
    "        \n",
    "        all_feature_metadata, train_data_means, train_data_std, \\\n",
    "                     bins, forest, best_features_per_cluster, model_per_cluster = train_it(train_data, my_n_clusters)\n",
    "\n",
    "        input_for_model, pred = apply_on_test(train_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                     clustering_columns, bins, forest, best_features_per_cluster, model_per_cluster)\n",
    "        res = pred.join(slope)\n",
    "        fold_train_rmse = np.sqrt(np.mean((res.prediction - res.ALSFRS_slope) ** 2))\n",
    "\n",
    "        input_for_model, pred = apply_on_test(test_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                     clustering_columns, bins, forest, best_features_per_cluster, model_per_cluster)\n",
    "        res = pred.join(slope)\n",
    "        fold_test_rmse += np.sqrt(np.mean((res.prediction - res.ALSFRS_slope) ** 2))\n",
    "        \n",
    "        input_for_model.to_csv('../x_results/test_%d_input_for_model.csv' % fold,sep='|')\n",
    "        res.to_csv('../x_results/test_%d_prediction.csv' % fold,sep='|')\n",
    "\n",
    "        fold += 1\n",
    "        print \"fold RMS Error train, test: \", fold_train_rmse, fold_test_rmse\n",
    "        train_rmse += fold_train_rmse\n",
    "        test_rmse += fold_test_rmse\n",
    "\n",
    "        tock = datetime.now()   \n",
    "        diff = tock - tick \n",
    "        print \"minutes for fold: \", diff.seconds / 60\n",
    "\n",
    "            \n",
    "    print \"X-validated RMS Error train, test: \", train_rmse / kf.n_folds, test_rmse / kf.n_folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "************************************************************\n",
      "\n",
      "******************************\n",
      "fold: 0\n",
      "train_data:  (1616, 145) (1616, 1)\n",
      "train cluster cnt:  [323 323 323 323 324]\n",
      "cluster: 0 with size: (323, 146) with mean target: -1.18324478115 std: 0.765767251086\n",
      "best we can do with all features: 0.756029078052\n",
      "adding best family: ('respiratory', 0.74864553066423289) time: 1.84099984169\n",
      "adding best family: ('Monocytes', 0.73517132383034056) time: 2.04699993134\n",
      "adding best family: ('Race', 0.72082989004365416) time: 2.51699995995\n",
      "adding best family: ('weight', 0.71184367142664862) time: 3.38100004196\n",
      "adding best family: ('Total Cholesterol', 0.70472369303363758) time: 10.503000021\n",
      "adding best family: ('Alkaline Phosphatase', 0.69574616673062428) time: 12.5180001259\n",
      "cluster: 1 with size: (323, 146) with mean target: -0.85739851173 std: 0.620179903326\n",
      "best we can do with all features: 0.605698508808\n",
      "adding best family: ('Total Cholesterol', 0.60646247872011361) time: 1.77600002289\n",
      "adding best family: ('Race', 0.59847480489808547) time: 2.25499987602\n",
      "adding best family: ('respiratory', 0.59299521694073953) time: 2.98200011253\n",
      "adding best family: ('CK', 0.58528131506218595) time: 3.55400013924\n",
      "adding best family: ('Calcium', 0.57807969289783601) time: 4.60300016403\n",
      "adding best family: ('fvc_percent', 0.57154983269036919) time: 5.77600002289\n",
      "cluster: 2 with size: (323, 146) with mean target: -0.71719789579 std: 0.525370534326\n",
      "best we can do with all features: 0.524556636805\n",
      "adding best family: ('onset_delta', 0.51912736946359683) time: 1.76399993896\n",
      "adding best family: ('respiratory', 0.51455399905068544) time: 1.79399991035\n",
      "adding best family: ('Protein', 0.51100135347690356) time: 2.28000020981\n",
      "adding best family: ('White Blood Cell (WBC)', 0.50644252785908961) time: 3.40600013733\n",
      "adding best family: ('Total Cholesterol', 0.50146378147167681) time: 3.91499996185\n",
      "adding best family: ('Chloride', 0.4984802613304008) time: 6.26900005341\n",
      "cluster: 3 with size: (323, 146) with mean target: -0.536371973937 std: 0.493286817779\n",
      "best we can do with all features: 0.490784360475\n",
      "adding best family: ('Albumin', 0.48211261248264647) time: 1.83700013161\n",
      "adding best family: ('Race', 0.47354615674115519) time: 2.1850001812\n",
      "adding best family: ('weight', 0.4658932041717524) time: 2.97500014305\n",
      "adding best family: ('bp_diastolic', 0.45470929585324193) time: 9.31299996376\n",
      "adding best family: ('Creatinine', 0.44916550891847679) time: 8.67899990082\n",
      "adding best family: ('CK', 0.44465077835916833) time: 10.5759999752\n",
      "cluster: 4 with size: (324, 146) with mean target: -0.335351878669 std: 0.358032932873\n",
      "best we can do with all features: 0.348971256157\n",
      "adding best family: ('Creatinine', 0.34730743309732121) time: 2.1139998436\n",
      "adding best family: ('mouth', 0.34204011872783013) time: 2.31699991226\n",
      "adding best family: ('Blood Urea Nitrogen (BUN)', 0.34019995266924891) time: 4.59399986267\n",
      "adding best family: ('Calcium', 0.33629126553099403) time: 6.26099991798\n",
      "adding best family: ('fvc_percent', 0.33458651271325224) time: 7.00100016594\n",
      "adding best family: ('Sodium', 0.33292551275196586) time: 7.84000015259\n",
      "best_features_per_cluster:  {0: ['respiratory', 'weight', 'Alkaline Phosphatase', 'Race', 'Monocytes', 'Total Cholesterol'], 1: ['CK', 'respiratory', 'Calcium', 'Race', 'Total Cholesterol', 'fvc_percent'], 2: ['respiratory', 'White Blood Cell (WBC)', 'Total Cholesterol', 'onset_delta', 'Protein', 'Chloride'], 3: ['CK', 'weight', 'bp_diastolic', 'Race', 'Creatinine', 'Albumin'], 4: ['Sodium', 'Calcium', 'mouth', 'Blood Urea Nitrogen (BUN)', 'Creatinine', 'fvc_percent']}\n",
      "cluster: 0 size: (323L,)\n",
      "\t RMS error (0 is perfect): 0.70\n",
      "\t explained variance score (1 is perfect): 0.17\n",
      "3 sample predictions:  [-1.30409262 -1.24381751 -1.05587427]\n",
      "cluster: 1 size: (323L,)\n",
      "\t RMS error (0 is perfect): 0.57\n",
      "\t explained variance score (1 is perfect): 0.15\n",
      "3 sample predictions:  [-0.74439662 -0.89730025 -0.73103584]\n",
      "cluster: 2 size: (323L,)\n",
      "\t RMS error (0 is perfect): 0.50\n",
      "\t explained variance score (1 is perfect): 0.10\n",
      "3 sample predictions:  [-0.97690076 -0.70158385 -0.64134631]\n",
      "cluster: 3 size: (323L,)\n",
      "\t RMS error (0 is perfect): 0.44\n",
      "\t explained variance score (1 is perfect): 0.18\n",
      "3 sample predictions:  [-0.45728744 -0.54731564 -0.58060434]\n",
      "cluster: 4 size: (324L,)\n",
      "\t RMS error (0 is perfect): 0.33\n",
      "\t explained variance score (1 is perfect): 0.13\n",
      "3 sample predictions:  [-0.36241696 -0.33020184 -0.20025639]\n",
      "applying on:  (1616, 145)\n",
      "applied cluster cnt:  [323 323 323 323 324]\n",
      "applying on:  (808, 145)\n",
      "applied cluster cnt:  [209 133 149 149 168]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fold_test_rmse' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-95abae42c6ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e12728e71763>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(df, slope, my_n_clusters)\u001b[0m\n\u001b[0;32m     23\u001b[0m                      clustering_columns, bins, forest, best_features_per_cluster, model_per_cluster)\n\u001b[0;32m     24\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mfold_test_rmse\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALSFRS_slope\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0minput_for_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../x_results/test_%d_input_for_model.csv'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'fold_test_rmse' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2, 4):\n",
    "    print \"*\"*60\n",
    "    print \"*\"*60\n",
    "    train_and_test(df, slope, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
