{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Methods used for vectorizing the raw data \n",
    "* Used several times across our flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define all kind of vectorization and aggregation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions\n",
    "Should receive (df, feature_name) and return a DataFrame with SubjectID as an index and columns for features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar -> Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scalar_feature_to_dummies_core(df, feature_metadata):\n",
    "    my_slice = df[df.feature_name == feature_metadata[\"feature_name\"]]\n",
    "    if my_slice.shape[0] == 0:\n",
    "        return pd.DataFrame()\n",
    "    my_slice_pivot = pd.pivot_table(my_slice, values = ['feature_value'], index = ['SubjectID'], \n",
    "                                columns = ['feature_name'], aggfunc = lambda x:x)\n",
    "    dum = pd.get_dummies(my_slice_pivot['feature_value'][feature_metadata[\"feature_name\"]])\n",
    "    return dum\n",
    "\n",
    "def learn_scalar_feature_to_dummies(df, feature_metadata):\n",
    "    dum = scalar_feature_to_dummies_core(df, feature_metadata)\n",
    "    return dum.columns\n",
    "\n",
    "def apply_scalar_feature_to_dummies(df, feature_metadata):\n",
    "    dum = scalar_feature_to_dummies_core(df, feature_metadata)\n",
    "    return dum.reindex(columns = feature_metadata[\"derived_features\"], fill_value=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series functions\n",
    "Are invoked per SubjectID and with the valid timeframe data only (<92 days). Should receive a DataFrame with 'feature_value', and 'feature_delta' and return a dict from col_suffix (e.g. \"last\", \"mean\", ...) to the value\n",
    "\n",
    "NOTE: here theres no learned model - we apply the same hard-coded treatment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries -> Slope, %diff, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ts_pct_diff(ts_data, feature_metadata):\n",
    "    if len(ts_data) < 2:\n",
    "        return { \"pct_diff\": None }\n",
    "    \n",
    "    ts_data_sorted = ts_data.sort('feature_delta')\n",
    "    values = ts_data_sorted.feature_value.astype('float')\n",
    "    time_values = ts_data_sorted.feature_delta.astype('float')\n",
    "\n",
    "    time_diff = time_values.iloc[-1] - time_values.iloc[0]\n",
    "    val = ( values.iloc[-1] - values.iloc[0] ) / ( values.iloc[0] * time_diff)\n",
    "    if val == float('inf'):\n",
    "        return { \"pct_diff\": None }\n",
    "    \n",
    "    return { \"pct_diff\": val }\n",
    "    \n",
    "def ts_stats(ts_data, feature_metadata):\n",
    "    if len(ts_data) < 1:\n",
    "        return { \"mean\": None, \"std\": None, \"median\": None }\n",
    "    \n",
    "    values = ts_data.feature_value.astype('float')\n",
    "    return { \"mean\": values.mean(), \"std\": values.std(), \"median\": values.median() }\n",
    "    \n",
    "def ts_mean_slope(ts_data, feature_metadata):\n",
    "    if len(ts_data) < 2:\n",
    "        return { \"mean_slope\": None }\n",
    "    \n",
    "    ts_data_sorted = ts_data.sort('feature_delta') \n",
    "    ts_data_sorted.feature_value = ts_data_sorted.feature_value.astype('float')\n",
    "    first, others = ts_data_sorted.iloc[0], ts_data_sorted.iloc[1:]\n",
    "    slopes = [ ( x[1].feature_value - first.feature_value) / ( x[1].feature_delta - first.feature_delta ) for x in others.iterrows() ]\n",
    "    slopes = [ x for x in slopes if x!=float('inf') ]\n",
    "    return { \"mean_slope\": np.mean(slopes) }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries -> last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ts_last_value(ts_data, feature_metadata):\n",
    "    if len(ts_data) < 1:\n",
    "        return { \"last\": None }\n",
    "    \n",
    "    ts_data_sorted = ts_data.sort('feature_delta') \n",
    "    return { \"last\": ts_data_sorted.feature_value.astype('float').iloc[-1] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ts_last_boolean(ts_data, feature_metadata):\n",
    "    if len(ts_data) < 1:\n",
    "        return { \"last\": None }\n",
    "    val_str = str(ts_data.feature_value.iloc[-1]).lower()\n",
    "    if val_str == 'y' or val_str == 'true':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return { \"last\": val }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Static part of our metadata - which feature maps to which vectorizing func?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_funcs_to_features = [ \n",
    "    { \n",
    "        \"funcs\": [ ts_stats, ts_mean_slope, ts_pct_diff, ts_last_value ],\n",
    "        \"features\": [\n",
    "            'ALSFRS_Total', 'weight', 'Albumin', 'Creatinine',\n",
    "            'bp_diastolic', 'bp_systolic', 'pulse', 'respiratory_rate', 'temperature',\n",
    "            'mouth', 'respiratory', 'hands', 'fvc_percent'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"funcs\": ts_last_value,\n",
    "        \"features\": [\n",
    "            'BMI', 'Age', 'onset_delta',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"funcs\": ts_last_boolean,\n",
    "        \"features\": [\n",
    "            'family_ALS_hist',\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "dummy_funcs_to_features = [ \n",
    "    { \n",
    "        \"funcs\": apply_scalar_feature_to_dummies,\n",
    "        \"features\": [ 'Gender', 'Race' ]\n",
    "    }   \n",
    "]\n",
    "\n",
    "def invert_func_to_features(ftf, feature_type):\n",
    "    res = {}\n",
    "    for ff in ftf:\n",
    "        funcs = ff['funcs']\n",
    "        features = ff['features']\n",
    "        if not type(funcs) is list:\n",
    "            funcs = [funcs] # a single function\n",
    "        for func in funcs: \n",
    "            for feature in features:\n",
    "                if feature not in res:\n",
    "                    res[feature] = {\"feature_name\": feature, \"funcs\": set(), \n",
    "                                    \"feature_type\": feature_type, \"derived_features\": set()}\n",
    "                res[feature][\"funcs\"].add(func)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_to_dummies_model(df, all_feature_metadata):\n",
    "    new_metadata = all_feature_metadata.copy()\n",
    "    for feature, fv in all_feature_metadata.iteritems():\n",
    "        if fv[\"feature_type\"] == \"dummy\":\n",
    "            for func in fv[\"funcs\"]:\n",
    "                new_metadata[feature][\"derived_features\"] = learn_scalar_feature_to_dummies(df, fv)\n",
    "    return new_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_series(f):\n",
    "    def foo(x, args):\n",
    "        res = f(x, args)\n",
    "        return pd.Series(res)\n",
    "    return foo\n",
    "\n",
    "def parse_feature_delta(fd):\n",
    "    \"\"\" parse feature_delta which can be given in strange forms, such as '54;59' \"\"\"\n",
    "    if type(fd) is float or type(fd) is np.float64: return fd\n",
    "    first_value = fd.split(';')[0]\n",
    "    try:\n",
    "        return float(first_value)\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def vectorize(df, all_feature_metadata, debug=False):\n",
    "    vectorized = pd.DataFrame(index=df.SubjectID.unique().astype(str)) # SubjectID is always str for later joins\n",
    "    df.loc[:,'feature_delta'] = df.feature_delta.apply(parse_feature_delta)\n",
    "    pointintime_data = df[df.feature_delta < 92]\n",
    "    pointintime_data = pointintime_data.drop_duplicates(subset = ['SubjectID', 'feature_name' ,'feature_delta'], take_last=True)\n",
    "    new_metadata = all_feature_metadata.copy()\n",
    "    for feature, fm in all_feature_metadata.iteritems():\n",
    "        feature_ts_data = pointintime_data[pointintime_data.feature_name == feature]\n",
    "        for func in fm[\"funcs\"]:\n",
    "            if fm[\"feature_type\"] == \"dummy\":\n",
    "                res = func(df, fm)\n",
    "            elif fm[\"feature_type\"] == \"ts\":    \n",
    "                res = pd.DataFrame(feature_ts_data.groupby('SubjectID').apply(to_series(func), args=fm))\n",
    "                res.columns = [ feature + \"_\" + str(col_suffix) for col_suffix in res.columns ]\n",
    "                for col in res.columns:\n",
    "                    new_metadata[feature][\"derived_features\"].add(col)\n",
    "            else:\n",
    "                raise Exception(\"unknown feature type: \" + fv[\"feature_type\"])\n",
    "            vectorized = pd.merge(vectorized, res, how='left', right_index=True, left_index=True)\n",
    "        if debug:\n",
    "            print feature\n",
    "\n",
    "    vectorized.index.name='SubjectID'\n",
    "    return vectorized, new_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(vectorized, all_feature_metadata, train_data_means, train_data_std):\n",
    "    vectorized = vectorized.reindex(columns=train_data_means.keys())\n",
    "    normalized = vectorized.fillna(train_data_means)\n",
    "    for feature, fm in all_feature_metadata.iteritems():\n",
    "        for col in fm[\"derived_features\"]:\n",
    "            data = normalized[col].astype('float')\n",
    "            normalized.loc[:, col] = (data - train_data_means[col])/train_data_std[col]\n",
    "    return normalized, all_feature_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
