{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run selector.sh\n",
    "As specified in the challenge - we must run our selector logic subject by subject.\n",
    "\n",
    "The output_file_path must have the following format:\n",
    "* First line: the cluster identifier for that patient\n",
    "* Following lines: the selected features selected for that specific single patient, using the same format as the input data. A maximum of 6 features are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0\n",
      "60879|Lab Test|Creatinine|51|umol/L|174.0\n",
      "60879|Lab Test|Creatinine|63|umol/L|0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "from vectorizing_funcs import *\n",
    "\n",
    "if \"IPython\" not in sys.argv[0]:\n",
    "    models_folder, input_file, output_file= sys.argv[1], sys.argv[2], sys.argv[3]\n",
    "else:\n",
    "    models_folder, input_file, output_file= \"../\", \"../60879.txt\", \"../selected_60879.txt\"\n",
    "\n",
    "all_feature_metadata = pickle.load( open(models_folder + '/all_feature_metadata.pickle', 'rb') )\n",
    "train_data_means = pickle.load( open(models_folder + '/all_data_means.pickle', 'rb') )\n",
    "train_data_std = pickle.load( open(models_folder + '/all_data_std.pickle', 'rb') )\n",
    "clustering_model = pickle.load( open(models_folder + '/clustering_model.pickle', 'rb') )\n",
    "best_features_per_cluster = pickle.load( open(models_folder + '/best_features_per_cluster.pickle', 'rb') )\n",
    "   \n",
    "df = pd.read_csv(input_file, sep = '|', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "for subj in df.SubjectID.unique()[:3]:\n",
    "    df_subj = df[df.SubjectID == subj]\n",
    "    vectorized, _ = vectorize(df_subj, all_feature_metadata)\n",
    "    normalized, _ = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "    cluster_data = normalized[clustering_model[\"columns\"]]\n",
    "    c = clustering_model[\"model\"].predict(cluster_data)[0]\n",
    "    buf = \"cluster: %d\\n\" % c\n",
    "    selected = df_subj[df_subj.feature_name.isin(best_features_per_cluster[c])]\n",
    "    buf += selected.to_csv(sep='|', index = False, header = False)\n",
    "    print buf\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(buf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
