{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Builds all our models x-validated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from StringIO import StringIO\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from vectorizing_funcs import *\n",
    "from modeling_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:  (1642927, 6) 2424\n",
      "slope:  (2424, 1) 2424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>form_name</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_value</th>\n",
       "      <th>feature_unit</th>\n",
       "      <th>feature_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>533</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Gender</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>533</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Age</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubjectID    form_name feature_name feature_value feature_unit feature_delta\n",
       "0       533  Demographic       Gender             F          NaN           0.0\n",
       "1       533  Demographic          Age            65          NaN           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALSFRS_slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubjectID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>-0.965608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>-0.921717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ALSFRS_slope\n",
       "SubjectID              \n",
       "533           -0.965608\n",
       "649           -0.921717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../all_data.csv', sep = '|', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "slope = pd.read_csv('../all_slope.csv', sep = '|', index_col=\"SubjectID\")\n",
    "slope.index = slope.index.astype(str)\n",
    "\n",
    "print \"df: \", df.shape, df.SubjectID.unique().size\n",
    "print \"slope: \", slope.shape, slope.index.unique().size\n",
    "display(df.head(2))\n",
    "display(slope.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = invert_func_to_features(ts_funcs_to_features, \"ts\")\n",
    "metadata.update(invert_func_to_features(dummy_funcs_to_features, \"dummy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering_columns = [u'Asian', u'Black', u'Hispanic', u'Other', u'Unknown', u'White',\n",
    "       u'mouth_last', u'mouth_mean_slope',u'hands_last',\n",
    "       u'hands_mean_slope',u'onset_delta_last', u'ALSFRS_Total_last',\n",
    "       u'ALSFRS_Total_mean_slope',u'BMI_last', u'fvc_percent_mean_slope', \n",
    "                     u'respiratory_last', u'respiratory_mean_slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_on_test(test_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                 clustering_columns, kmeans, best_features_per_cluster, model_per_cluster):\n",
    "    \n",
    "    # Vectorizing\n",
    "    vectorized, _ = vectorize(test_data, all_feature_metadata)\n",
    "    normalized, _ = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "    \n",
    "    # Clustering\n",
    "    \n",
    "    print \n",
    "    for_clustering = normalized[clustering_columns]\n",
    "    clusters = pd.DataFrame(index = for_clustering.index.astype(str))\n",
    "    clusters['cluster'] = kmeans.predict(for_clustering)\n",
    "    print \"cluster cnt: \", np.bincount(kmeans.labels_)\n",
    "\n",
    "    X = normalized.join(clusters)\n",
    "    \n",
    "    buf = filter_only_selected_features(test_data.set_index(\"SubjectID\"), clusters, \\\n",
    "                                        best_features_per_cluster)    \n",
    "    s_df = pd.read_csv(StringIO(buf), sep='|', index_col=False, dtype='unicode')\n",
    "    s_vectorized, _ = vectorize(s_df, all_feature_metadata)\n",
    "    s_normalized, _ = normalize(s_vectorized, all_feature_metadata, train_data_means, train_data_std)    \n",
    "    s_X = s_normalized.join(clusters)    \n",
    "\n",
    "    pred = s_X.apply(apply_model, args=[model_per_cluster], axis = 1)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(df, slope, all_feature_metadata, my_n_clusters=3):\n",
    "    kf = KFold(df.SubjectID.unique().size, n_folds=3)\n",
    "    fold, test_rmse, train_rmse = 0, 0.0, 0.0\n",
    "\n",
    "    for train, test in kf:\n",
    "        train_data = df[df.SubjectID.isin(df.SubjectID.unique()[train])]\n",
    "        test_data = df[df.SubjectID.isin(df.SubjectID.unique()[test])]\n",
    "        print\n",
    "        print \"*\"*30\n",
    "        print \"fold: %d\" % fold\n",
    "        print \"train_data: \", train_data.shape, train_data.SubjectID.unique().size, \\\n",
    "                train_data.SubjectID.min(), train_data.SubjectID.max()\n",
    "\n",
    "        # Vectorizing\n",
    "        all_feature_metadata = learn_to_dummies_model(train_data, all_feature_metadata)\n",
    "        vectorized, all_feature_metadata = vectorize(train_data, all_feature_metadata)\n",
    "        train_data_means = vectorized.mean()\n",
    "        train_data_std = vectorized.std()            \n",
    "        normalized, all_feature_metadata = normalize(vectorized, all_feature_metadata, train_data_means, train_data_std)\n",
    "\n",
    "        # Clustering\n",
    "        for_clustering = normalized[clustering_columns]\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=my_n_clusters)\n",
    "        #Note we must convert to str to join with slope later\n",
    "        clusters = pd.DataFrame(index = for_clustering.index.astype(str))\n",
    "        clusters['cluster'] = kmeans.fit_predict(for_clustering)\n",
    "        print \"cluster cnt: \", np.bincount(kmeans.labels_)\n",
    "\n",
    "        X = normalized.join(clusters)\n",
    "        Y = slope.join(clusters)\n",
    "\n",
    "        best_features_per_cluster = get_best_features_per_cluster(X, Y, all_feature_metadata)\n",
    "        print \"best_features_per_cluster: \", best_features_per_cluster \n",
    "        buf = filter_only_selected_features(train_data.set_index(\"SubjectID\"), clusters, \\\n",
    "                                            best_features_per_cluster)\n",
    "\n",
    "        s_df = pd.read_csv(StringIO(buf), sep='|', index_col=False, dtype='unicode')\n",
    "        s_vectorized, _ = vectorize(s_df, all_feature_metadata)\n",
    "        s_normalized, _ = normalize(s_vectorized, all_feature_metadata, train_data_means, train_data_std)    \n",
    "        s_X = s_normalized.join(clusters)\n",
    "\n",
    "        model_per_cluster = get_model_per_cluster(s_X, Y)\n",
    "\n",
    "        pred = apply_on_test(train_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                     clustering_columns, kmeans, best_features_per_cluster, model_per_cluster)\n",
    "        res = pred.join(slope)\n",
    "        train_rmse += np.sqrt(np.mean((res.prediction - res.ALSFRS_slope) ** 2))\n",
    "\n",
    "        pred = apply_on_test(test_data, all_feature_metadata, train_data_means, train_data_std, \n",
    "                     clustering_columns, kmeans, best_features_per_cluster, model_per_cluster)\n",
    "        res = pred.join(slope)\n",
    "        test_rmse += np.sqrt(np.mean((res.prediction - res.ALSFRS_slope) ** 2))\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    print \"Train RMS Error: \", train_rmse / kf.n_folds\n",
    "    print \"Test RMS Error: \", test_rmse / kf.n_folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "************************************************************\n",
      "\n",
      "******************************\n",
      "fold: 0\n",
      "train_data:  (1095759, 6) 1616 332486 999482\n",
      "cluster cnt:  [ 507   78 1031]\n",
      "best_features_per_cluster:  {0: ['Age', 'BMI', 'Gender', 'Race', 'family_ALS_hist', 'pulse'], 1: ['Age', 'BMI', 'Gender', 'Race', 'bp_systolic', 'family_ALS_hist'], 2: ['Age', 'BMI', 'Gender', 'Race', 'family_ALS_hist', 'temperature']}\n",
      "cluster: 0 size: (507L,)\n",
      "root mean square error (0 is perfect): 0.63\n",
      "Explained variance score (1 is perfect): -0.00\n",
      "\n",
      "cluster: 1 size: (78L,)\n",
      "root mean square error (0 is perfect): 0.61\n",
      "Explained variance score (1 is perfect): 0.08\n",
      "\n",
      "cluster: 2 size: (1031L,)\n",
      "root mean square error (0 is perfect): 0.63\n",
      "Explained variance score (1 is perfect): 0.00\n",
      "\n",
      "\n",
      "cluster cnt:  [ 507   78 1031]\n",
      "Train root mean square error (0 is perfect): 0.63\n",
      "\n",
      "cluster cnt:  [ 507   78 1031]\n",
      "Test root mean square error (0 is perfect): 0.62\n",
      "\n",
      "******************************\n",
      "fold: 1\n",
      "train_data:  (1088370, 6) 1616 100256 999482\n",
      "cluster cnt:  [1020  512   84]\n",
      "best_features_per_cluster:  {0: ['Age', 'BMI', 'Gender', 'Race', 'family_ALS_hist', 'respiratory_rate'], 1: ['Age', 'BMI', 'Gender', 'Race', 'bp_systolic', 'family_ALS_hist'], 2: ['Age', 'Albumin', 'BMI', 'Gender', 'Race', 'family_ALS_hist']}\n",
      "cluster: 0 size: (1020L,)\n",
      "root mean square error (0 is perfect): 0.62\n",
      "Explained variance score (1 is perfect): 0.00\n",
      "\n",
      "cluster: 1 size: (512L,)\n",
      "root mean square error (0 is perfect): 0.59\n",
      "Explained variance score (1 is perfect): 0.01\n",
      "\n",
      "cluster: 2 size: (84L,)\n",
      "root mean square error (0 is perfect): 0.57\n",
      "Explained variance score (1 is perfect): 0.21\n",
      "\n",
      "\n",
      "cluster cnt:  [1020  512   84]\n",
      "Train root mean square error (0 is perfect): 0.62\n",
      "\n",
      "cluster cnt:  [1020  512   84]\n",
      "Test root mean square error (0 is perfect): 0.66\n",
      "\n",
      "******************************\n",
      "fold: 2\n",
      "train_data:  (1101725, 6) 1616 100256 99728\n",
      "cluster cnt:  [ 531   72 1013]\n",
      "best_features_per_cluster:  {0: ['Age', 'BMI', 'Gender', 'Race', 'bp_systolic', 'family_ALS_hist'], 1: ['Age', 'BMI', 'Race', 'family_ALS_hist', 'respiratory', 'respiratory_rate'], 2: ['Age', 'BMI', 'Gender', 'Race', 'family_ALS_hist', 'respiratory_rate']}\n",
      "cluster: 0 size: (531L,)\n",
      "root mean square error (0 is perfect): 0.62\n",
      "Explained variance score (1 is perfect): 0.01\n",
      "\n",
      "cluster: 1 size: (72L,)\n",
      "root mean square error (0 is perfect): 0.63\n",
      "Explained variance score (1 is perfect): 0.17\n",
      "\n",
      "cluster: 2 size: (1013L,)\n",
      "root mean square error (0 is perfect): 0.63\n",
      "Explained variance score (1 is perfect): 0.01\n",
      "\n",
      "\n",
      "cluster cnt:  [ 531   72 1013]\n",
      "Train root mean square error (0 is perfect): 0.65\n",
      "\n",
      "cluster cnt:  [ 531   72 1013]\n",
      "Test root mean square error (0 is perfect): 0.65\n",
      "RMSE:  0.643217551971\n",
      "************************************************************\n",
      "************************************************************\n",
      "\n",
      "******************************\n",
      "fold: 0\n",
      "train_data:  (1095759, 6) 1616 332486 999482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-facb544d76b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-469cf814c28a>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(df, slope, all_feature_metadata, my_n_clusters)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Vectorizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mall_feature_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_to_dummies_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_feature_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mvectorized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_feature_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_feature_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_data_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtrain_data_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\src\\p4l-als-z-team\\ipython-notebooks\\vectorizing_funcs.pyc\u001b[0m in \u001b[0;36mvectorize\u001b[1;34m(df, all_feature_metadata, debug)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"feature_type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ts\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_ts_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SubjectID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_suffix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_suffix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                     \u001b[0mnew_metadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"derived_features\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode.chained_assignment'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[1;32m--> 675\u001b[1;33m                                                    self.axis)\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         return self._wrap_applied_output(keys, values,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 hasattr(splitter, 'fast_apply') and axis == 0):\n\u001b[0;32m   1277\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidApply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mfast_apply\u001b[1;34m(self, f, names)\u001b[0m\n\u001b[0;32m   3467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m         \u001b[0msdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3469\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3471\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.apply_frame_axis0 (pandas\\lib.c:39500)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mf\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\src\\p4l-als-z-team\\ipython-notebooks\\vectorizing_funcs.pyc\u001b[0m in \u001b[0;36mfoo\u001b[1;34m(x, args)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_feature_delta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    166\u001b[0m                         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_try_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m                         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# python2 - MultiIndex fails on mixed types\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m# other iterable of some kind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m   2351\u001b[0m             or hasattr(values, '__array__')):\n\u001b[0;32m   2352\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2353\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2354\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_clusters in range(3, 7):\n",
    "    print \"*\"*60\n",
    "    print \"*\"*60\n",
    "    train_and_test(df, slope, metadata, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
